import re
import os
from collections import defaultdict
from torch.utils.tensorboard import SummaryWriter


def parse_mask_rcnn_single_log(log_path, output_dir):
    """è§£æå•ä¸ªMask R-CNNæ—¥å¿—æ–‡ä»¶ç”Ÿæˆå¯è§†åŒ–æ•°æ®"""
    os.makedirs(output_dir, exist_ok=True)
    writer = SummaryWriter(log_dir=output_dir)

    # åˆå§‹åŒ–æ•°æ®ç»“æ„
    metrics = defaultdict(lambda: {
        'train_loss': [],
        'val_bbox': defaultdict(list),
        'val_segm': defaultdict(list)
    })

    # ===== æ­£åˆ™è¡¨è¾¾å¼è§„åˆ™ =====
    train_pattern = re.compile(
        r"Epoch\(train\)\s+\[(\d+)\].*?loss:\s+([\d\.]+)"
    )

    val_pattern = re.compile(
        r"Epoch\(val\)\s+\[(\d+)\].*?"
        r"coco/bbox_mAP:\s+([\d\.]+).*?"
        r"coco/bbox_mAP_50:\s+([\d\.]+).*?"
        r"coco/bbox_mAP_75:\s+([\d\.]+).*?"
        r"coco/bbox_mAP_s:\s+([\d\.]+).*?"
        r"coco/bbox_mAP_m:\s+([\d\.]+).*?"
        r"coco/bbox_mAP_l:\s+([\d\.]+).*?"
        r"coco/segm_mAP:\s+([\d\.]+).*?"
        r"coco/segm_mAP_50:\s+([\d\.]+).*?"
        r"coco/segm_mAP_75:\s+([\d\.]+).*?"
        r"coco/segm_mAP_s:\s+([\d\.]+).*?"
        r"coco/segm_mAP_m:\s+([\d\.]+).*?"
        r"coco/segm_mAP_l:\s+([\d\.]+)"
    )

    # ===== è§£ææ—¥å¿—å†…å®¹ =====
    print(f"ğŸ” æ­£åœ¨è§£ææ—¥å¿—æ–‡ä»¶: {log_path}")
    with open(log_path, 'r', encoding='gbk', errors='ignore') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue

            # è§£æè®­ç»ƒæŸå¤±
            if 'Epoch(train)' in line:
                train_match = train_pattern.search(line)
                if train_match:
                    epoch = int(train_match.group(1))
                    loss = float(train_match.group(2))
                    metrics[epoch]['train_loss'].append(loss)

            # è§£æéªŒè¯æŒ‡æ ‡
            elif 'Epoch(val)' in line:
                val_match = val_pattern.search(line)
                if val_match:
                    epoch = int(val_match.group(1))
                    # æå–bboxæŒ‡æ ‡
                    metrics[epoch]['val_bbox']['mAP'].append(float(val_match.group(2)))
                    metrics[epoch]['val_bbox']['mAP_50'].append(float(val_match.group(3)))
                    metrics[epoch]['val_bbox']['mAP_75'].append(float(val_match.group(4)))
                    metrics[epoch]['val_bbox']['AP_s'].append(float(val_match.group(5)))
                    metrics[epoch]['val_bbox']['AP_m'].append(float(val_match.group(6)))
                    metrics[epoch]['val_bbox']['AP_l'].append(float(val_match.group(7)))

                    # æå–segmæŒ‡æ ‡
                    metrics[epoch]['val_segm']['mAP'].append(float(val_match.group(8)))
                    metrics[epoch]['val_segm']['mAP_50'].append(float(val_match.group(9)))
                    metrics[epoch]['val_segm']['mAP_75'].append(float(val_match.group(10)))
                    metrics[epoch]['val_segm']['AP_s'].append(float(val_match.group(11)))
                    metrics[epoch]['val_segm']['AP_m'].append(float(val_match.group(12)))
                    metrics[epoch]['val_segm']['AP_l'].append(float(val_match.group(13)))

    # ===== å†™å…¥TensorBoard =====
    print("\nğŸ”„ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–æ•°æ®...")
    for epoch in sorted(metrics.keys()):
        # è®­ç»ƒæŸå¤±ï¼ˆå–å¹³å‡å€¼ï¼‰
        if metrics[epoch]['train_loss']:
            avg_loss = sum(metrics[epoch]['train_loss']) / len(metrics[epoch]['train_loss'])
            writer.add_scalar('0_Train/Loss', avg_loss, epoch)

        # éªŒè¯æŒ‡æ ‡ï¼ˆå–æœ€åä¸€æ¬¡è®°å½•ï¼‰
        if metrics[epoch]['val_bbox']:
            writer.add_scalar('1_Validation/bbox/mAP', metrics[epoch]['val_bbox']['mAP'][-1], epoch)
            writer.add_scalar('1_Validation/bbox/mAP_50', metrics[epoch]['val_bbox']['mAP_50'][-1], epoch)
            writer.add_scalar('1_Validation/bbox/mAP_75', metrics[epoch]['val_bbox']['mAP_75'][-1], epoch)
            writer.add_scalar('1_Validation/bbox/AP_small', metrics[epoch]['val_bbox']['AP_s'][-1], epoch)
            writer.add_scalar('1_Validation/bbox/AP_medium', metrics[epoch]['val_bbox']['AP_m'][-1], epoch)
            writer.add_scalar('1_Validation/bbox/AP_large', metrics[epoch]['val_bbox']['AP_l'][-1], epoch)

        if metrics[epoch]['val_segm']:
            writer.add_scalar('2_Validation/segm/mAP', metrics[epoch]['val_segm']['mAP'][-1], epoch)
            writer.add_scalar('2_Validation/segm/mAP_50', metrics[epoch]['val_segm']['mAP_50'][-1], epoch)
            writer.add_scalar('2_Validation/segm/mAP_75', metrics[epoch]['val_segm']['mAP_75'][-1], epoch)
            writer.add_scalar('2_Validation/segm/AP_small', metrics[epoch]['val_segm']['AP_s'][-1], epoch)
            writer.add_scalar('2_Validation/segm/AP_medium', metrics[epoch]['val_segm']['AP_m'][-1], epoch)
            writer.add_scalar('2_Validation/segm/AP_large', metrics[epoch]['val_segm']['AP_l'][-1], epoch)

    writer.close()
    print(f"âœ… æ•°æ®å·²ä¿å­˜è‡³ï¼š{os.path.abspath(output_dir)}")


if __name__ == "__main__":
    # ===== é…ç½®å‚æ•° =====
    log_file = r"work_dirs\mask_rcnn_r50_voc_coco\20250519_152917\20250519_152917.log"
    output_dir = os.path.join(os.getcwd(), "mask_rcnn_tensorboard_single")

    # ===== æ‰§è¡Œè§£æ =====
    parse_mask_rcnn_single_log(
        log_path=log_file,
        output_dir=output_dir
    )